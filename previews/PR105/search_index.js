var documenterSearchIndex = {"docs":
[{"location":"datahandling/#DataHandling","page":"DataHandling","title":"DataHandling","text":"","category":"section"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"The DataHandling module is responsible for reading data from files and resampling it onto the simulation grid.","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"This is no trivial task. Among the challenges:","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"data can be large and cannot be read all in one go and/or held in memory,\nregridding onto the simulation grid can be very expensive,\nIO can be very expensive,\nCPU/GPU communication can be a bottleneck.","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"The DataHandling takes the divide and conquer approach: the various core tasks and features and split into other independent modules (chiefly FileReaders, and Regridders). Such modules can be developed, tested, and extended independently (as long as they maintain a consistent interface). For instance, if need arises, the DataHandler can be used (almost) directly to process files with a different format from NetCDF.","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"The key struct in DataHandling is the DataHandler. The DataHandler contains one or more FileReader(s), a Regridder, and other metadata necessary to perform its operations (e.g., target ClimaCore.Space). The DataHandler can be used for static or temporal data, and exposes the following key functions:","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"regridded_snapshot(time): to obtain the regridded field at the given time.                   time has to be available in the data.\navailable_times (available_dates): to list all the times (dates) over                   which the data is defined.\nprevious_time(time/date) (next_time(time/date)): to obtain the time of the                        snapshot before the given time or date. This can be                        used to compute the interpolation weight for linear                        interpolation, or in combination with                        regridded_snapshot to read a particular snapshot","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"Most DataHandling functions take either time or date, with the difference being that time is intended as \"simulation time\" and is expected to be in seconds; date is a calendar date (from Dates.DateTime). Conversion between time and date is performed using the reference date and simulation starting time provided to the DataHandler.","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"The DataHandler has a caching mechanism in place: once a field is read and regridded, it is stored in the local cache to be used again (if needed). This is a least-recently-used (LRU) cache implemented in DataStructures, which removes the least-recently-used data when its maximum size is reached. The default maximum size is 128.","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"While the reading backend could be generic, at the moment, this module uses only the NCFileReader.","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"This extension is loaded when loading ClimaCore and NCDatasets are loaded. In addition to this, a Regridder is needed (which might require importing additional packages) - see Regridders for more information.","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"It is possible to pass down keyword arguments to underlying constructors in DataHandler with the regridder_kwargs and file_reader_kwargs. These have to be a named tuple or a dictionary that maps Symbols to values.","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"A DataHandler can contain information about a variable that we read directly from an input file, or about a variable that is produced by composing data from multiple input variables. In the latter case, the input variables may either all come from the same input file, or may each come from a separate input file. The user must provide the composing function, which operates pointwise on each of the inputs, as well as an ordered list of the variable names to be passed to the function. Additionally, input variables that are composed together must have the same spatial and temporal dimensions. Note that, if a non-identity pre-processing function is provided as part of file_reader_kwargs, it will be applied to each input variable before they are composed. Composing multiple input variables is currently only supported with the InterpolationsRegridder, not with TempestRegridder.","category":"page"},{"location":"datahandling/#Example:-Linear-interpolation-of-a-single-data-variable","page":"DataHandling","title":"Example: Linear interpolation of a single data variable","text":"","category":"section"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"As an example, let us implement a simple linear interpolation for a variable u defined in the era5_example.nc NetCDF file. The file contains monthly averages starting from the year 2000.","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"import ClimaUtilities.DataHandling\nimport ClimaCore\nimport NCDatasets\n# Loading ClimaCore and Interpolations automatically loads DataHandling\nimport Interpolations\n# This will load InterpolationsRegridder\n\nimport Dates\n\n# Define pre-processing function to convert units of input\nunit_conversion_func = (data) -> 1000 * data\n\ndata_handler = DataHandling.DataHandler(\"era5_example.nc\",\n                                        \"u\",\n                                        target_space,\n                                        reference_date = Dates.DateTime(2000, 1, 1),\n                                        regridder_type = :InterpolationsRegridder,\n                                        file_reader_kwargs = (; preprocess_func = unit_conversion_func))\n\nfunction linear_interpolation(data_handler, time)\n    # Time is assumed to be \"simulation time\", ie seconds starting from reference_date\n\n    time_of_prev_snapshot = DataHandling.previous_time(data_handler, time)\n    time_of_next_snapshot = DataHandling.next_time(data_handler, time)\n\n    prev_snapshot = DataHandling.regridded_snaphsot(data_handler, time_of_prev_snapshot)\n    next_snapshot = DataHandling.regridded_snaphsot(data_handler, time_of_next_snapshot)\n\n    # prev and next snapshots are ClimaCore.Fields defined on the target_space\n\n    return @. prev_snapshot + (next_snapshot - prev_snapshot) *\n        (time - time_of_prev_snapshot) / (time_of_next_snapshot - time_of_prev_snapshot)\nend","category":"page"},{"location":"datahandling/#Example-appendix:-Using-multiple-input-data-variables","page":"DataHandling","title":"Example appendix: Using multiple input data variables","text":"","category":"section"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"Suppose that the input NetCDF file era5_example.nc contains two variables u and v, and we care about their sum u + v but not their individual values. We can provide a pointwise composing function to perform the sum, along with the InterpolationsRegridder to produce the data we want, u + v. The preprocess_func passed in file_reader_kwargs will be applied to u and to v individually, before the composing function is applied. The regridding is applied after the composing function. u and v could also come from separate NetCDF files, but they must still have the same spatial and temporal dimensions.","category":"page"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"# Define the pointwise composing function we want, a simple sum in this case\ncompose_function = (x, y) -> x + y\ndata_handler = DataHandling.DataHandler(\"era5_example.nc\",\n                                        [\"u\", \"v\"],\n                                        target_space,\n                                        reference_date = Dates.DateTime(2000, 1, 1),\n                                        regridder_type = :InterpolationsRegridder,\n                                        file_reader_kwargs = (; preprocess_func = unit_conversion_func),\n                                        compose_function)","category":"page"},{"location":"datahandling/#API","page":"DataHandling","title":"API","text":"","category":"section"},{"location":"datahandling/","page":"DataHandling","title":"DataHandling","text":"ClimaUtilities.DataHandling.DataHandler\nClimaUtilities.DataHandling.available_times\nClimaUtilities.DataHandling.available_dates\nClimaUtilities.DataHandling.previous_time\nClimaUtilities.DataHandling.next_time\nClimaUtilities.DataHandling.regridded_snapshot\nClimaUtilities.DataHandling.regridded_snapshot!\nClimaUtilities.DataHandling.dt\nClimaUtilities.DataHandling.time_to_date\nClimaUtilities.DataHandling.date_to_time","category":"page"},{"location":"datahandling/#ClimaUtilities.DataHandling.DataHandler","page":"DataHandling","title":"ClimaUtilities.DataHandling.DataHandler","text":"DataHandler(file_paths::Union{AbstractString, AbstractArray{<:AbstractString}},\n            varnames::Union{AbstractString, AbstractArray{<:AbstractString}},\n            target_space::ClimaCore.Spaces.AbstractSpace;\n            reference_date::Dates.DateTime = Dates.DateTime(1979, 1, 1),\n            t_start::AbstractFloat = 0.0,\n            regridder_type = nothing,\n            cache_max_size::Int = 128,\n            regridder_kwargs = (),\n            file_reader_kwargs = ())\n\nCreate a DataHandler to read varnames from file_paths and remap them to target_space. file_paths may contain either one path for all variables or one path for each variable. In the latter case, the entries of file_paths and varnames are expected to match based on position.\n\nThe DataHandler maintains an LRU cache of Fields that were previously computed.\n\nPositional arguments\n\nfile_paths: Paths of the NetCDF file(s) that contain the input data.\nvarnames: Names of the datasets in the NetCDF that have to be read and processed.\ntarget_space: Space where the simulation is run, where the data has to be regridded to.\n\nKeyword arguments\n\nTime/date information will be ignored for static input files. (They are still set to make everything more type stable.)\n\nreference_date: Calendar date corresponding to the start of the simulation.\nt_start: Simulation time at the beginning of the simulation. Typically this is 0            (seconds), but if might be different if the simulation was restarted.\nregridder_type: What type of regridding to perform. Currently, the ones implemented are                   :TempestRegridder (using TempestRemap) and                   :InterpolationsRegridder (using Interpolations.jl). TempestRemap                   regrids everything ahead of time and saves the result to HDF5 files.                   Interpolations.jl is online and GPU compatible but not conservative.                   If the regridder type is not specified by the user, and multiple are                   available, the default :InterpolationsRegridder regridder is used.\ncache_max_size: Maximum number of regridded fields to store in the cache. If the cache                   is full, the least recently used field is removed.\nregridder_kwargs: Additional keywords to be passed to the constructor of the regridder.                     It can be a NamedTuple, or a Dictionary that maps Symbols to values.\nfile_reader_kwargs: Additional keywords to be passed to the constructor of the file reader.                       It can be a NamedTuple, or a Dictionary that maps Symbols to values.\ncompose_function: Function to combine multiple input variables into a single data variable.                   The default, to be used in the case of one input variable, is the identity.                   Note that the order of varnames must match the argument order of compose_function.\n\n\n\n\n\n","category":"function"},{"location":"datahandling/#ClimaUtilities.DataHandling.available_times","page":"DataHandling","title":"ClimaUtilities.DataHandling.available_times","text":"available_times(data_handler::DataHandler)\n\nReturn the time in seconds of the snapshots in the data, measured considering the starting time of the simulation and the reference date\n\n\n\n\n\n","category":"function"},{"location":"datahandling/#ClimaUtilities.DataHandling.available_dates","page":"DataHandling","title":"ClimaUtilities.DataHandling.available_dates","text":"available_dates(data_handler::DataHandler)\n\nReturn the dates of the snapshots in the data.\n\n\n\n\n\n","category":"function"},{"location":"datahandling/#ClimaUtilities.DataHandling.previous_time","page":"DataHandling","title":"ClimaUtilities.DataHandling.previous_time","text":"previous_time(data_handler::DataHandler, time::AbstractFloat)\nprevious_time(data_handler::DataHandler, date::Dates.DateTime)\n\nReturn the time in seconds of the snapshot before the given time. If time is one of the snapshots, return itself.\n\nIf time is not in the data_handler, return an error.\n\n\n\n\n\n","category":"function"},{"location":"datahandling/#ClimaUtilities.DataHandling.next_time","page":"DataHandling","title":"ClimaUtilities.DataHandling.next_time","text":"next_time(data_handler::DataHandler, time::AbstractFloat)\nnext_time(data_handler::DataHandler, date::Dates.DateTime)\n\nReturn the time in seconds of the snapshot after the given time. If time is one of the snapshots, return the next time.\n\nIf time is not in the data_handler, return an error.\n\n\n\n\n\n","category":"function"},{"location":"datahandling/#ClimaUtilities.DataHandling.regridded_snapshot","page":"DataHandling","title":"ClimaUtilities.DataHandling.regridded_snapshot","text":"regridded_snapshot(data_handler::DataHandler, date::Dates.DateTime)\nregridded_snapshot(data_handler::DataHandler, time::AbstractFloat)\nregridded_snapshot(data_handler::DataHandler)\n\nReturn the regridded snapshot from data_handler associated to the given time (if relevant).\n\nThe time has to be available in the data_handler.\n\nWhen using multiple input variables, the varnames argument determines the order of arguments to the compose_function function used to produce the data variable.\n\nregridded_snapshot potentially modifies the internal state of data_handler and it might be a very expensive operation.\n\n\n\n\n\n","category":"function"},{"location":"datahandling/#ClimaUtilities.DataHandling.regridded_snapshot!","page":"DataHandling","title":"ClimaUtilities.DataHandling.regridded_snapshot!","text":"regridded_snapshot!(dest::ClimaCore.Fields.Field, data_handler::DataHandler, date::Dates.DateTime)\n\nWrite to dest the regridded snapshot from data_handler associated to the given time.\n\nThe time has to be available in the data_handler.\n\nregridded_snapshot! potentially modifies the internal state of data_handler and it might be a very expensive operation.\n\n\n\n\n\n","category":"function"},{"location":"datahandling/#ClimaUtilities.DataHandling.dt","page":"DataHandling","title":"ClimaUtilities.DataHandling.dt","text":"dt(data_handler::DataHandler)\n\nReturn the time interval between data points for the data in data_handler.\n\nThis requires the data to be defined on a equispaced temporal mesh.\n\n\n\n\n\n","category":"function"},{"location":"datahandling/#ClimaUtilities.DataHandling.time_to_date","page":"DataHandling","title":"ClimaUtilities.DataHandling.time_to_date","text":"time_to_date(data_handler::DataHandler, time::AbstractFloat)\n\nConvert the given time to a calendar date.\n\ndate = reference_date + t_start + time\n\n\n\n\n\n","category":"function"},{"location":"datahandling/#ClimaUtilities.DataHandling.date_to_time","page":"DataHandling","title":"ClimaUtilities.DataHandling.date_to_time","text":"date_to_time(data_handler::DataHandler, time::AbstractFloat)\n\nConvert the given calendar date to a time (in seconds).\n\ndate = reference_date + t_start + time\n\n\n\n\n\n","category":"function"},{"location":"outputpathgenerator/#OutputPathGenerator","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"","category":"section"},{"location":"outputpathgenerator/","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"The OutputPathGenerator module provides tools for preparing the directory structure for your simulation output. This helps you organize your simulation results efficiently and avoid overwriting existing data.","category":"page"},{"location":"outputpathgenerator/","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"The module offers one function, generate_output_path. The function takes three arguments:","category":"page"},{"location":"outputpathgenerator/","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"output_path: The base directory path for your simulation output.\nstyle (Optional): The desired style for output management (defaults to ActiveLinkStyle).\ncontext (Optional): the ClimaComms.context. This is required in MPI runs to ensure that all the MPI processes agree on the folder structure.","category":"page"},{"location":"outputpathgenerator/","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"The function processes the output_path based on the chosen style and returns the final path where you should write your simulation output.","category":"page"},{"location":"outputpathgenerator/","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"You should use generate_output_path at the beginning of your simulation and use the return value as the base directory where you save all the output your code produces.","category":"page"},{"location":"outputpathgenerator/#Available-Styles","page":"OutputPathGenerator","title":"Available Styles","text":"","category":"section"},{"location":"outputpathgenerator/","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"The module currently offers two different styles for handling the output directory:","category":"page"},{"location":"outputpathgenerator/#RemovePreexistingStyle-(Destructive)","page":"OutputPathGenerator","title":"RemovePreexistingStyle (Destructive)","text":"","category":"section"},{"location":"outputpathgenerator/","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"This style directly uses the provided output_path as the final output directory. Important: If a directory already exists at the specified path, it will be removed completely (including any subfolders and files) without confirmation. Use this style cautiously!","category":"page"},{"location":"outputpathgenerator/#ActiveLinkStyle-(Non-Destructive)","page":"OutputPathGenerator","title":"ActiveLinkStyle (Non-Destructive)","text":"","category":"section"},{"location":"outputpathgenerator/","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"This style provides a more convenient and non-destructive approach. It manages a sequence of subfolders within the base directory specified by outputpath. It also creates a symbolic link named `outputactive` that points to the current active subfolder. This allows you to easily access the latest simulation results.","category":"page"},{"location":"outputpathgenerator/#Example","page":"OutputPathGenerator","title":"Example","text":"","category":"section"},{"location":"outputpathgenerator/","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"Let's assume your output_path is set to data.","category":"page"},{"location":"outputpathgenerator/","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"If data doesn't exist, the module creates it and returns data/output_0000. In doing this, a link data/output_active to data/output_0000 is created so that you can always access your data in data/output_active.\nIf data exists and contains an output_active link pointing to data/output_0005, output_active is updated to point to a new subfolder called data/output_0006\nIf data exists with or without an output_active link, the module checks for existing subfolders named data/output_XXXX (with XXXX a number). If none are found, it creates data/output_0000 and a link data/output_active pointing to it.","category":"page"},{"location":"outputpathgenerator/#A-note-for-Windows-users","page":"OutputPathGenerator","title":"A note for Windows users","text":"","category":"section"},{"location":"outputpathgenerator/","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"Windows does not always allow the creation of symbolic links by unprivileged users, so some details about links might be slightly different depending on your system. If you are using Windows, please have a look at docstring on the ActiveLinkStyle to learn more about possible differences.","category":"page"},{"location":"outputpathgenerator/#API","page":"OutputPathGenerator","title":"API","text":"","category":"section"},{"location":"outputpathgenerator/","page":"OutputPathGenerator","title":"OutputPathGenerator","text":"ClimaUtilities.OutputPathGenerator.generate_output_path\nClimaUtilities.OutputPathGenerator.RemovePreexistingStyle\nClimaUtilities.OutputPathGenerator.ActiveLinkStyle","category":"page"},{"location":"outputpathgenerator/#ClimaUtilities.OutputPathGenerator.generate_output_path","page":"OutputPathGenerator","title":"ClimaUtilities.OutputPathGenerator.generate_output_path","text":"generate_output_path(output_path,\n                     context = nothing,\n                     style::OutputPathGeneratorStyle = ActiveLinkStyle())\n\nProcess the output_path and return a string with the path where to write the output.\n\nThe context is a ClimaComms context and is required for MPI runs.\n\nHow the output should be structured (in terms of directory tree) is determined by the style.\n\nStyles\n\nRemovePreexistingStyle: the output_path provided is the actual output path. If a directory already exists there, remove it without asking for confirmation.\nActiveLinkStyle: the output_path returned is a new folder of the form output_path/output_1234, where the number is incremented every time this function is called. ActiveLinkStyle also creates a link output_path/output_active that ensures that the most recent output is always accessible at the output_path/output_active path. This is style is non-destructive.\n\n(Note, \"styles\" have nothing to do with Julia traits.)\n\n\n\n\n\ngenerate_output_path(::RemovePreexistingStyle, output_path, context = nothing)\n\nDocumentation for this function is in the RemovePreexistingStyle struct.\n\n\n\n\n\ngenerate_output_path(::ActiveLinkStyle, output_path, context = nothing)\n\nDocumentation for this function is in the ActiveLinkStyle struct.\n\n\n\n\n\n","category":"function"},{"location":"outputpathgenerator/#ClimaUtilities.OutputPathGenerator.RemovePreexistingStyle","page":"OutputPathGenerator","title":"ClimaUtilities.OutputPathGenerator.RemovePreexistingStyle","text":"RemovePreexistingStyle\n\nWith this option, the output directory is directly specified. If the directory already exists, remove it. No confirmation is asked, so use at your own risk.\n\n\n\n\n\n","category":"type"},{"location":"outputpathgenerator/#ClimaUtilities.OutputPathGenerator.ActiveLinkStyle","page":"OutputPathGenerator","title":"ClimaUtilities.OutputPathGenerator.ActiveLinkStyle","text":"ActiveLinkStyle\n\nThis style generates a unique output path within a base directory specified by output_path. It ensures the base directory exists and creates it if necessary. Additionally, it manages a sequence of subfolders and a symbolic link named \"output_active\" for convenient access to the active output location.\n\nThis style is designed to:\n\nbe non-destructive,\nprovide a deterministic and fixed path for the latest available data,\nand have nearly zero runtime overhead.\n\ngenerate_output_path returns path to the newly created folder with the next available increment (of the form output_1234), and ensures that a valid output_active link points to that folder.\n\nExamples:\n\nLet us assume that output_path = dormouse.\n\ndormouse does not exist in the current working directory: ActiveLinkStyle will create it and return dormouse/output_0000. In the process, a symlink dormouse/output_active is also created. This symlink points to dormouse/output_0000.\ndormouse exists and contains a output_active link that points to dormouse/output_0005, ActiveLinkStyle will a create new directory dormouse/output_0006, return this path, and change the output_active to point to this directory.\ndormouse exists and does not contain a output_active, ActiveLinkStyle will check if any dormouse/output_XXXX exists. If not, it creates dormouse/output_0000 and a link dormouse/output_active that points to this directory.\n\nA note for Windows users\n\nWindows does not always allow the creation of symbolic links by unprivileged users. This depends on the version of Windows, but also some of its settings. When the creation of symbolic links is not possible, OutputPathGenerator will create NTFS junction points instead. Junction points are similar to symbolic links, with the main difference that they have to refer to directories and they have to be absolute paths. As a result, on systems that do not allow unprivileged users to create symbolic links, moving the base output folder results in breaking the output_active link.\n\n\n\n\n\n","category":"type"},{"location":"regridders/#Regridders","page":"Regridders","title":"Regridders","text":"","category":"section"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"Simulations often need to import external data directly onto the computational grid. The Regridders module implements different schemes to accomplish this goal.","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"Currently, Regridders comes with two implementations:","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"TempestRegridder uses TempestRemap (through ClimaCoreTempestRemap) to perform conservative interpolation onto lat-long grids. TempestRegridder only works for single-threaded CPU runs and works directly with files.\nInterpolationsRegridder uses Interpolations.jl to perform non-conservative linear interpolation onto lat-long(-z) grids. InterpolationsRegridder works directly with data.","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"⚠️ Note: While the Regridders can be used independently, most users will find their needs are immediately met by the SpaceVaryingInputs and TimeVaryingInputs interfaces. These higher-level objects implement everything that is needed to read a file to the model grid (internally using the Regridders).","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"If a regridder type is not specified by the user, and multiple are available, the InterpolationsRegridder will be used by default. At least one regridder extension must be loaded to be able to use regridding.","category":"page"},{"location":"regridders/#TempestRegridder","page":"Regridders","title":"TempestRegridder","text":"","category":"section"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"This extension is loaded when loading ClimaCoreTempestRemap","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"TempestRegridder performs conservative interpolation of lat-lon grids onto computational domains. TempestRegridder performs all the interpolation ahead of time and saves the regridded fields to HDF5 files that can be read during the simulation.","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"Currently, TempestRegridder does not support regridding on 3D domains. The InterpolationsRegridder described below can be used for these cases.","category":"page"},{"location":"regridders/#Example","page":"Regridders","title":"Example","text":"","category":"section"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"Assuming target_space is a ClimaCore 2D spherical field, the input data is the variable u in the file era5_example.nc, and we want to read the data associated with date target_date.","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"import ClimaUtilities.Regridders\nimport ClimaCoreTempestRemap\n# Loading ClimaCoreTempest automatically loads TempestRegridder\n\nreg = Regridders.TempestRegridder(target_space, \"regrid_output\", \"u\", \"era5_example.nc\")\n# When reg is created, the variable `u` is regridded and the output files\n# are saved to the `regrid_output` folder\n\nregridded_u = Regridders.regrid(reg, target_date)","category":"page"},{"location":"regridders/#InterpolationsRegridder","page":"Regridders","title":"InterpolationsRegridder","text":"","category":"section"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"This extension is loaded when loading ClimaCore and Interpolations","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"InterpolationsRegridder performs linear interpolation of input data (linear along each direction) and returns a ClimaCore Field defined on the target_space.","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"Currently, InterpolationsRegridder only supports spherical shells and extruded spherical shells (but it could be easily extended to other domains).","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"Note: it is easy to change the spatial interpolation type if needed.","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"InterpolationsRegridder are created once, they are tied to a target_space, but can be used with any input data. With MPI runs, every process computes the interpolating function. This is always done on the CPU and moved to GPU for accelerated runs.","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"By default, InterpolationsRegridder assumes you are interpolating on a globe and the default extrapolation boundary conditions are: periodic (along longitudes), copy (along latitude), and throwing an error (along z). These can be changed by passing the extrapolation_bc to the constructor of the regridder.","category":"page"},{"location":"regridders/#FAQ:-How-do-I-enable-linear-extrapolation-in-z?","page":"Regridders","title":"FAQ: How do I enable linear extrapolation in z?","text":"","category":"section"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"Create the regridder like this:","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"import Interpolations as Intp\n\nextrapolation_bc = (Intp.Periodic(), Intp.Flat(), Intp.Linear())\nregridder = InterpolationsRegridder(target_space; extrapolation_bc)","category":"page"},{"location":"regridders/#Example-2","page":"Regridders","title":"Example","text":"","category":"section"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"Assuming target_space is a ClimaCore 2D spherical field.","category":"page"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"import ClimaUtilities.Regridders\nimport ClimaCore, Interpolations\n# Loading ClimaCore and Interpolations automatically loads InterpolationsRegridder\n\nreg = Regridders.InterpolationsRegridder(target_space)\n\n# Now we can regrid any data\nlon = collect(-180:1:180)\nlat = collect(-90:1:90)\n# It has to be lon, lat (because this is the assumed order in the CF conventions)\ndimensions = (lon, lat)\n\ndata = rand((length(lon), length(lat)))\n\ninterpolated_data = Regridders.InterpolationsRegridder(reg, data, dimensions)\ninterpolated_2data = Regridders.InterpolationsRegridder(reg, 2 .* data, dimensions)","category":"page"},{"location":"regridders/#API","page":"Regridders","title":"API","text":"","category":"section"},{"location":"regridders/","page":"Regridders","title":"Regridders","text":"ClimaUtilities.Regridders.TempestRegridder\nClimaUtilities.Regridders.InterpolationsRegridder\nClimaUtilities.Regridders.regrid","category":"page"},{"location":"regridders/#ClimaUtilities.Regridders.InterpolationsRegridder","page":"Regridders","title":"ClimaUtilities.Regridders.InterpolationsRegridder","text":"InterpolationsRegridder(target_space::ClimaCore.Spaces.AbstractSpace\n                        [; extrapolation_bc::Tuple])\n\nAn online regridder that uses Interpolations.jl\n\nCurrently, InterpolationsRegridder is only implemented for LatLong and LatLongZ spaces. It performs linear interpolation along each of the directions (separately). By default, it imposes periodic boundary conditions for longitude, flat for latitude, and throwing errors when extrapolating in z. This can be customized by passing the extrapolation_bc keyword argument.\n\nInterpolationsRegridder is GPU and MPI compatible in the simplest possible way: each MPI process has the entire input data and everything is copied to GPU.\n\nKeyword arguments\n\nThe optional keyword argument extrapolation_bc controls what should be done when the interpolation point is not in the domain of definition. This has to be a tuple of N elements, where N is the number of spatial dimensions. For 3D spaces, the default is (Interpolations.Periodic(), Interpolations.Flat(), Interpolations.Throw()).\n\n\n\n\n\n","category":"function"},{"location":"regridders/#ClimaUtilities.Regridders.regrid","page":"Regridders","title":"ClimaUtilities.Regridders.regrid","text":"regrid(regridder::InterpolationsRegridder, data, dimensions)::Field\n\nRegrid the given data as defined on the given dimensions to the target_space in regridder.\n\nThis function is allocating.\n\n\n\n\n\n","category":"function"},{"location":"climaartifacts/#ClimaArtifacts","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"","category":"section"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"Julia artifacts are pieces of data that can be distributed alongside a package. Julia artifacts were developed to distribute application binaries (e.g., compiled libraries). In CliMA, we use them to distribute data required to perform our simulations (e.g., input data).","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"The ClimaArtifacts module extends the Julia artifact system to solve two issues:","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"Ensuring that artifacts can be gracefully acquired by parallel runs;\nTagging artifacts that are accessed during a simulation.","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"We will examine these two problems below. In the meantime, this entire documentation page can be summarized in a one short directive for package developers:","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"Instead of accessing artifacts with  ArtifactWrappers.jl or using  Julia artifacts directly, use the @clima_artifact macro instead.","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"Also, keep in mind that","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"⚠️ Note: Julia artifacts are always entire folders, never single files!","category":"page"},{"location":"climaartifacts/#Julia-artifacts-and-MPI","page":"ClimaArtifacts","title":"Julia artifacts and MPI","text":"","category":"section"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"Package developers can specify one of two modes for any given artifact: greedy (default) or lazy download. Artifact that are not marked as lazy are automatically downloaded by Julia when the package is instantiated. On the other hand, lazy artifacts are downloaded the first time they are accessed.","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"CliMA packages can distribute tens of artifacts that are relevant for very different types of simulations, and it is a good idea to mark artifacts as lazy unless they are strictly required for the operation of the package (e.g., the orbital parameters in Insolation.jl).","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"Lazy artifacts are incompatible with MPI. In parallel runs, each process tries to download the same file, resulting in a race condition and corrupted files (not to mention tens of processing pinging the same server at the same time). ClimaArtifacts implements a new macro, @clima_artifact, to solve this problem.","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"@clima_artifact is a near drop-in replacement for the @artifact_str Julia macro.","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"For greedy artifacts and non-MPI runs, it is possible to simply call @clima_artifact(artifact_name). This will return the path of the artifact folder. This macro will fail for lazy artifacts. In that case, one has to also pass the ClimaComms.jl context. The context is required because @clima_artifact needs to synchronize different MPI processes.","category":"page"},{"location":"climaartifacts/#Example","page":"ClimaArtifacts","title":"Example","text":"","category":"section"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"This extension is loaded when loading ClimaComms","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"Assume socrates is a lazy artifact, we can access the socrates artifact folder as in","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"using ClimaUtilities.ClimaArtifacts\n# If the artifact is lazy, we also need LazyArtifacts\nusing LazyArtifacts\n\nimport ClimaComms\n# When loading ClimaComms, a Julia extension for ClimaUtilities will be loaded\n\nmy_mpi_context = ClimaComms.context()\n\nsocrates_path_folder = @clima_artifact(\"socrates\", context)","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"The @clima_artifact macro is executed at parse time when the argument is a literal string (e.g., @clima_artifact(\"socrates\")), and at runtime when it is a variable @clima_artifact(artifact_name).","category":"page"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"Note: context is a positional argument, not a keyword one. Calling @clima_artifact(\"socrates\"; context) will fail. (This is due to how Julia macros handle keyword arguments)","category":"page"},{"location":"climaartifacts/#Tagging-artifacts","page":"ClimaArtifacts","title":"Tagging artifacts","text":"","category":"section"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"A full climate simulation requires lots of external input data. Most of this data comes from scientific experiments that have to be properly acknowledged. ClimaArtifacts allows users to know what artifacts were used in a given simulation. As long as artifacts are being accessed with @clima_artifacts, the ClimaArtifacts keeps track of what is being used. The set of artifacts accessed can be obtained with ClimaArtifacts.accessed_artifacts.","category":"page"},{"location":"climaartifacts/#Example-2","page":"ClimaArtifacts","title":"Example","text":"","category":"section"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"using ClimaUtilities.ClimaArtifacts\nart1 = @clima_artifact(\"socrates\")\nart2 = @clima_artifact(\"zeno\")\n\nClimaArtifacts.accessed_artifacts()\n# Set([\"socrates\", \"zeno\"])","category":"page"},{"location":"climaartifacts/#API","page":"ClimaArtifacts","title":"API","text":"","category":"section"},{"location":"climaartifacts/","page":"ClimaArtifacts","title":"ClimaArtifacts","text":"ClimaUtilities.ClimaArtifacts.@clima_artifact\nClimaUtilities.ClimaArtifacts.accessed_artifacts","category":"page"},{"location":"climaartifacts/#ClimaUtilities.ClimaArtifacts.@clima_artifact","page":"ClimaArtifacts","title":"ClimaUtilities.ClimaArtifacts.@clima_artifact","text":"@clima_artifact(artifact_name, context = nothing)\n\nReturn the path of the given artifact name. The path is always a folder (Julia artifacts can contain multiple files).\n\nThis macro plays nicely with MPI contexts and lazily downloaded artifacts. This is achieved by ensuring that only one process downloads the file, while the other wait until the file is fully downloaded.\n\nPassing the context is required only for lazy artifacts.\n\n\n\n\n\n","category":"macro"},{"location":"climaartifacts/#ClimaUtilities.ClimaArtifacts.accessed_artifacts","page":"ClimaArtifacts","title":"ClimaUtilities.ClimaArtifacts.accessed_artifacts","text":"accessed_artifacts()\n\nReturn a set with the names of the artifacts accessed using the @clima_artifact macro.\n\n\n\n\n\n","category":"function"},{"location":"datastructures/#DataStructures","page":"DataStructures","title":"DataStructures","text":"","category":"section"},{"location":"datastructures/","page":"DataStructures","title":"DataStructures","text":"The DataStructures module implements helpful data structures to be used by other ClimaUtilities.jl modules or external packages.","category":"page"},{"location":"datastructures/#LRUCache","page":"DataStructures","title":"LRUCache","text":"","category":"section"},{"location":"datastructures/","page":"DataStructures","title":"DataStructures","text":"DataStructures implements an LRUCache, which is used in both DataHandlingExt and NCFileReaderExt. LRUCache can be used to store pieces of information that need to be accessed multiple times and may be expensive to compute, such as regridded fields or loaded files. Instead of recomputing the values each time they're needed, the previously-computed information is saved in the cache and retrieved directly from it. To prevent the cache from growing so large that it takes up significant memory, the least-recently-used (LRU) scheme maintains a maximum cache size: every time adding an element to the cache would lead its size to grow larger thant the maximum allowed, the element that was accessed the least recently is deleted first.","category":"page"},{"location":"datastructures/","page":"DataStructures","title":"DataStructures","text":"Note: all the methods supported by dictionaries are currently implemented.","category":"page"},{"location":"datastructures/","page":"DataStructures","title":"DataStructures","text":"If you need one that is not implemented, please open an issue or a pull request.","category":"page"},{"location":"datastructures/#Example","page":"DataStructures","title":"Example","text":"","category":"section"},{"location":"datastructures/","page":"DataStructures","title":"DataStructures","text":"In many ways, LRUCaches behave like Julia dictionaries. To use one, we first need to initialize the empty cache specifying types of keys and values and optionally the maximum allowed size:","category":"page"},{"location":"datastructures/","page":"DataStructures","title":"DataStructures","text":"import ClimaUtilities.DataStructures\ncache = DataStructures.LRUCache{Int, Int}(; max_size = 128)","category":"page"},{"location":"datastructures/","page":"DataStructures","title":"DataStructures","text":"Once we have the cache, we can access and insert elements with get!. get! retrieves the value associated to the key if avaialble, otherwise it inserts a new key with a provided default. The default can be passed as third argument or can be the return statement of a function provided as first (as typically done in do blocks). Continuing the example above","category":"page"},{"location":"datastructures/","page":"DataStructures","title":"DataStructures","text":"println(\"The value associated to 1 is: \", get!(cache, 1, 10))\nother_value = get!(cache, 2) do\n    return 20\nend","category":"page"},{"location":"datastructures/","page":"DataStructures","title":"DataStructures","text":"This cache can be used to implement some recursive function more efficiently, as in the famous case of the factorial:","category":"page"},{"location":"datastructures/","page":"DataStructures","title":"DataStructures","text":"function factorial(n)\n    n in (0, 1) && return 1\n    return n * get!(cache, n - 1, factorial(n - 1))\nend\n# The first time we call factorial it will compute everything\n@time factorial(10)\n# The second time it will only compute the last element\n@time factorial(11)","category":"page"},{"location":"datastructures/#API","page":"DataStructures","title":"API","text":"","category":"section"},{"location":"datastructures/","page":"DataStructures","title":"DataStructures","text":"ClimaUtilities.DataStructures.LRUCache\nBase.get!\nBase.get\nBase.haskey\nBase.copy\nBase.deepcopy\nBase.empty\nBase.empty!\nBase.pop!\nBase.delete!\nBase.getindex\nBase.setindex!\nBase.length","category":"page"},{"location":"datastructures/#ClimaUtilities.DataStructures.LRUCache","page":"DataStructures","title":"ClimaUtilities.DataStructures.LRUCache","text":"LRUCache{K, V}(; max_size::Int = 128) where {K, V}\n\nConstruct an empty LRUCache with a maximum size of max_size.\n\n\n\n\n\n","category":"type"},{"location":"datastructures/#Base.get!","page":"DataStructures","title":"Base.get!","text":"Base.get!(cache::LRUCache{K, V}, key::K, default::V) where {K, V}\n\nGet the value associated with key in cache. If the key is not in the cache, add it with the value default. In any case, update the key's priority and make sure the cache doesn't exceed its maximum size.\n\n\n\n\n\nBase.get!(default::Callable, cache::LRUCache{K, V}, key::K) where {K, V}\n\nGet the value associated with key in cache. If the key is not in the cache, add it with the value default(). In any case, update the key's priority and make sure the cache doesn't exceed its maximum size.\n\nThis method is intended to be used with do block syntax.\n\n\n\n\n\n","category":"function"},{"location":"datastructures/#Base.get","page":"DataStructures","title":"Base.get","text":"Base.get(cache::LRUCache{K, V}, key::K, default::V)\n\nReturn the value associated with key in cache, or if key is not in cache, return default. \n\n\n\n\n\nBase.get(default::Callable, cache::LRUCache{K, V}, key::K)\n\nReturn the value associated with key in cache, or if the key is not in the cache, return f().\n\n\n\n\n\n","category":"function"},{"location":"datastructures/#Base.haskey","page":"DataStructures","title":"Base.haskey","text":"Base.haskey(cache::LRUCache{K, V}, key::K)\n\nReturn whether key has a mapping in cache. \n\n\n\n\n\n","category":"function"},{"location":"datastructures/#Base.copy","page":"DataStructures","title":"Base.copy","text":"Base.copy(cache::LRUCache{K, V})\n\nReturn a shallow copy of cache.\n\n\n\n\n\n","category":"function"},{"location":"datastructures/#Base.deepcopy","page":"DataStructures","title":"Base.deepcopy","text":"Base.deepcopy(cache::LRUCache{K, V})\n\nReturn a deep copy of cache.\n\n\n\n\n\n","category":"function"},{"location":"datastructures/#Base.empty","page":"DataStructures","title":"Base.empty","text":"Base.empty(cache::LRUCache{K, V}, key_type::DataType=K, value_type::DataType=V)\n\nCreate an empty LRUCache with keys of type key_type and values of type value_type.\n\nThe second and third arguments are optional and default to the input's keytype and valuetype.  If only one of the two type is specified, it is assumed to be the value_type, and key_type is  assumed to the key type of cache.\n\n\n\n\n\n","category":"function"},{"location":"datastructures/#Base.empty!","page":"DataStructures","title":"Base.empty!","text":"Base.empty!(cache::LRUCache{K, V})\n\nRemove all key/value mappings from the input and return the emptied input.\n\n\n\n\n\n","category":"function"},{"location":"datastructures/#Base.pop!","page":"DataStructures","title":"Base.pop!","text":"Base.pop!(cache::LRUCache{K, V}, key::K, [default::V])\n\nDelete the mapping for key in cache and return the associated value, or  if the key does not exist, return default or throw an error if default is not specified\n\n\n\n\n\n","category":"function"},{"location":"datastructures/#Base.delete!","page":"DataStructures","title":"Base.delete!","text":"Base.delete!(cache::LRUCache{K, V}, key::K)\n\nDelete mapping for key, if it is incache, and return cache\n\n\n\n\n\n","category":"function"},{"location":"datastructures/#Base.getindex","page":"DataStructures","title":"Base.getindex","text":"Base.getindex(cache::LRUCache{K, V}, key::K)\n\nReturn the mapping for key in cache.\n\n\n\n\n\n","category":"function"},{"location":"datastructures/#Base.setindex!","page":"DataStructures","title":"Base.setindex!","text":"Base.setindex!(cache::LRUCache{K, V}, value::V, key::K)\n\nStore the mapping from key to value in cache. Then, return cache.\n\n\n\n\n\n","category":"function"},{"location":"datastructures/#Base.length","page":"DataStructures","title":"Base.length","text":"Base.length(cache::LRUCache{K, V})\n\nReturn the number of elements in cache.\n\n\n\n\n\n","category":"function"},{"location":"timemanager/#TimeManager","page":"TimeManager","title":"TimeManager","text":"","category":"section"},{"location":"timemanager/","page":"TimeManager","title":"TimeManager","text":"This module contains functions that handle dates and times in simulations. The functions in this module often call functions from Julia's Dates module.","category":"page"},{"location":"timemanager/#TimeManager-API","page":"TimeManager","title":"TimeManager API","text":"","category":"section"},{"location":"timemanager/","page":"TimeManager","title":"TimeManager","text":"ClimaUtilities.TimeManager.to_datetime\nClimaUtilities.TimeManager.strdate_to_datetime\nClimaUtilities.TimeManager.datetime_to_strdate\nClimaUtilities.TimeManager.trigger_callback\nClimaUtilities.TimeManager.Monthly\nClimaUtilities.TimeManager.EveryTimestep","category":"page"},{"location":"timemanager/#ClimaUtilities.TimeManager.to_datetime","page":"TimeManager","title":"ClimaUtilities.TimeManager.to_datetime","text":"to_datetime(date)\n\nConvert a DateTime-like object (e.g. DateTimeNoLeap) to a DateTime. We need this since some data files we use contain DateTimeNoLeap objects for dates, which can't be used for math with DateTimes. The DateTimeNoLeap type uses the Gregorian calendar without leap years, while the DateTime type uses Gregorian calendar with leap years.\n\nFor consistency, all input data files should have dates converted to DateTime before being used in a simulation.\n\nThis function is similar to reinterpret in CFTime.jl.\n\nArguments\n\ndate: DateTime-like object to be converted to DateTime\n\n\n\n\n\n","category":"function"},{"location":"timemanager/#ClimaUtilities.TimeManager.strdate_to_datetime","page":"TimeManager","title":"ClimaUtilities.TimeManager.strdate_to_datetime","text":"strdate_to_datetime(strdate::String)\n\nConvert from String (\"YYYYMMDD\") to Date format, required by the official AMIP input files.\n\n\n\n\n\n","category":"function"},{"location":"timemanager/#ClimaUtilities.TimeManager.datetime_to_strdate","page":"TimeManager","title":"ClimaUtilities.TimeManager.datetime_to_strdate","text":"datetime_to_strdate(datetime::Dates.DateTime)\n\nConvert from DateTime to String (\"YYYYMMDD\") format.\n\n\n\n\n\n","category":"function"},{"location":"timemanager/#ClimaUtilities.TimeManager.trigger_callback","page":"TimeManager","title":"ClimaUtilities.TimeManager.trigger_callback","text":"trigger_callback(date_nextcall::Dates.DateTime,\n    date_current::Dates.DateTime,\n    ::Monthly,\n    func::Function,)\n\nIf the current date is equal to or later than the \"next call\" date at time 00:00:00, call the callback function and increment the next call date by one month. Otherwise, do nothing and leave the next call date unchanged.\n\nThe tuple of arguments func_args must match the types, number, and order of arguments expected by func.\n\nArguments\n\ndate_nextcall::DateTime the next date to call the callback function at or after\ndate_current::DateTime the current date of the simulation\nsave_freq::AbstractFrequency frequency with which to trigger callback\nfunc::Function function to be triggered if date is at or past the next call date\nfunc_args::Tuple a tuple of arguments to be passed into the callback function\n\n\n\n\n\n","category":"function"},{"location":"faqs/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"faqs/#Is-it-possible-to-preprocess-the-data-in-TimeVaryingInput-or-SpaceVaryingInput,-for-instance,-to-remove-NaNs-or-change-units?","page":"Frequently Asked Questions","title":"Is it possible to preprocess the data in TimeVaryingInput or SpaceVaryingInput, for instance, to remove NaNs or change units?","text":"","category":"section"},{"location":"faqs/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Yes, TimeVaryingInput and SpaceVaryingInput support this feature. TimeVaryingInput and SpaceVaryingInput that read NetCDF files use NCFileReader under the hood. NCFileReaders can be constructed with an optional keyword argument preprocess_func, a pointwise function that transforms the data read into something else. Inputs can be constructed to pass down this keyword argument. Let us have a look at an example. Suppose the file distances.nc contains a time-varying variable distance in centimeters, but we want it in meters.","category":"page"},{"location":"faqs/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Schematically,","category":"page"},{"location":"faqs/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"import ClimaUtilities: TimeVaryingInputs\nimport ClimaCore\nimport Interpolations\n# Loading ClimaCore, NCDatasets, Interpolations loads the extensions we need\n\n# target_space is defined somewhere and is our computational grid\n# reference_date is the simulation date\n\ndistance_tv = TimeVaryingInputs.TimeVaryingInput(\"distances.nc\",\n                                                  \"distance\",\n                                                  target_space;\n                                                  reference_date,\n                                                  file_reader_kwargs = (; preprocess_func = x -> 10x))","category":"page"},{"location":"#ClimaUtilities.jl","page":"Overview","title":"ClimaUtilities.jl","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"ClimaUtilities.jl provides a toolkit of functions that cover needs that are shared across repositories within the CliMA project.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"ClimaUtilities.jl is designed to have the minimum possible number of direct dependencies. Instead, everything is implemented in Julia extensions and modules are conditionally loaded when key packages are imported.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"ClimaUtilities.jl also aims to provide an abstraction to commonly required features (e.g., regridding), so that improvements can be made under the hood without affecting users.","category":"page"},{"location":"#Features","page":"Overview","title":"Features","text":"","category":"section"},{"location":"#ClimaArtifacts","page":"Overview","title":"ClimaArtifacts","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"ClimaArtifacts provides a MPI-safe way to lazily download artifacts and to tag artifacts that are being accessed in a given simulation.","category":"page"},{"location":"#SpaceVaryingInputs-and-TimeVaryingInputs","page":"Overview","title":"SpaceVaryingInputs and TimeVaryingInputs","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"SpaceVaryingInputs and TimeVaryingInputs provide functions to seamlessly map input to a Field. The input could be a function, a 1D array, a NetCDF file, and it could be static or time varying. SpaceVaryingInputs and TimeVaryingInputs objects can be evaluate!d to set the value of Field (potentially using the Regridders). TimeVaryingInputs implement linear and nearest neighbor interpolations.","category":"page"},{"location":"#FileReaders","page":"Overview","title":"FileReaders","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"The FileReaders module provides a way to efficiently read data from files. Efficiently might mean chunked/threaded/cached/something else. Currently, this is mostly and interface barrier to provide a path for future improvements.","category":"page"},{"location":"#Regridders","page":"Overview","title":"Regridders","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"ClimaUtilities comes with two modules to map rectangular grids two (extruded) finite spectral elements, InterpolationsRegridder and TempestRegridder. These modules are primarily used to ingest data and resample it onto the computational grid.","category":"page"},{"location":"#InterpolationsRegridder","page":"Overview","title":"InterpolationsRegridder","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"InterpolationsRegridder uses Interpolations.jl to perform non-conservative linear interpolation onto lat-long(-z) grids. InterpolationsRegridder is fully compatible with MPI/GPUs.","category":"page"},{"location":"#TempestRegridder","page":"Overview","title":"TempestRegridder","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"TempestRegridder uses TempestRemap to perform conservative interpolation onto lat-long grids.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"⚠️ Note: At the moment, TempestRegridder does not support MPI/GPUs and can only perform interpolation onto lat-long grids (not on z).","category":"page"},{"location":"#OutputPathGenerator","page":"Overview","title":"OutputPathGenerator","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"OutputPathGenerator handles the directory structure for the output of a simulation. If you are a package developer, use this module to set up the output path for your simulation.","category":"page"},{"location":"#DataHandling","page":"Overview","title":"DataHandling","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"The DataHandling module bundles a Regridder and a FileReader together to serve regridded fields at a given time upon request. The main interface for DataHandling is regridded_snapshot(data_handler, date), a function that returns a Field with data read from file for the given date. The DataHandler maintains an least-recently-used (LRU) cache of regridded fields to amortize the cost of (expensive) regridding operations.","category":"page"},{"location":"#DataStructures","page":"Overview","title":"DataStructures","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"The DataStructures module implements helpful data structures to be used by other ClimaUtilities.jl modules or external packages. Currently it contains an LRU cache that is used in DataHandlingExt and NCFileReaderExt.","category":"page"},{"location":"inputs/#SpaceVaringInputs-and-TimeVaryingInputs","page":"Space and Time Inputs","title":"SpaceVaringInputs and TimeVaryingInputs","text":"","category":"section"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"Most models require external inputs to work. Examples of inputs are an analytic function that prescribes the sea-surface temperature in time, or a file that describes the types of plants on the surface of the globe. The SpaceVaringInputs and TimeVaryingInputs modules provide a unified infrastructure to handle all these cases.","category":"page"},{"location":"inputs/#TimeVaryingInputs","page":"Space and Time Inputs","title":"TimeVaryingInputs","text":"","category":"section"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"This extension is loaded when loading ClimaCore is loaded. In addition to this, if NetCDF files are used, NCDatasets has to be loaded too. Finally, a Regridder is needed (which might require importing additional packages).","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"A TimeVaryingInput is an object that knows how to fill a ClimaCore Field at a given simulation time t. TimeVaryingInputs can be constructed in a variety of ways, from using analytic functions, to NetCDF data. They expose one interface, evaluate!(dest_field, tv, time), which can be used by model developers to update their Fields.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"This example shows that TimeVaryingInput can take different types of inputs and be used with a single interface (evaluate!). In all of this, TimeVaryingInputs internally handle all the complexity related to reading files (using FileReaders), dealing with parallelism and GPUs, regridding onto the computational domains (using Regridders and DataHandling), and so on.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"TimeVaryingInputs support:","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"analytic functions of time;\npairs of 1D arrays (for PointSpaces);\n2/3D NetCDF files (including composing multiple variables from one or more files into one variable);\nlinear interpolation in time (default), nearest neighbors, and \"period filling\";\nboundary conditions and repeating periodic data.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"It is possible to pass down keyword arguments to underlying constructors in the Regridder with the regridder_kwargs and file_reader_kwargs. These have to be a named tuple or a dictionary that maps Symbols to values.","category":"page"},{"location":"inputs/#NetCDF-file-inputs","page":"Space and Time Inputs","title":"NetCDF file inputs","text":"","category":"section"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"2D or 3D NetCDF files can be provided as inputs using TimeVaryingInputs. This could be a single variable provided in a single file, multiple variables provided in a single file, or multiple variables each coming from a unique file. When using multiple variables, a composing function must be provided as well, which will be used to combine the input variables into one data variable that is ultimately stored in the TimeVaryingInput. In this case, the order of variables provided in varnames determines the order of the arguments passed to the composing function.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"Note that if a non-identity pre-processing function is provided as part of file_reader_kwargs, it will be applied to each input variable before they are composed. All input variables to be composed together must have the same spatial and temporal dimensions.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"Composing multiple input variables is currently only supported with the InterpolationsRegridder, not with TempestRegridder. The regridding is applied after the pre-processing and composing.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"Composing multiple input variables in one Input is also possible with a SpaceVaryingInput, and everything mentioned here applies in that case.","category":"page"},{"location":"inputs/#Example:-NetCDF-file-input-with-multiple-input-variables","page":"Space and Time Inputs","title":"Example: NetCDF file input with multiple input variables","text":"","category":"section"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"Suppose that the input NetCDF file era5_example.nc contains two variables u and v, and we care about their sum u + v but not their individual values. We can provide a pointwise composing function to perform the sum, along with the InterpolationsRegridder to produce the data we want, u + v. The preprocess_func passed in file_reader_kwargs will be applied to u and to v individually, before the composing function is applied. The regridding is applied after the composing function. u and v could also come from separate NetCDF files, but they must still have the same spatial and temporal dimensions.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"# Define the pointwise composing function we want, a simple sum in this case\ncompose_function = (x, y) -> x + y\n# Define pre-processing function to convert units of input\nunit_conversion_func = (data) -> 1000 * data\n\ndata_handler = TimeVaryingInputs.TimeVaryingInput(\"era5_example.nc\",\n                                        [\"u\", \"v\"],\n                                        target_space,\n                                        reference_date = Dates.DateTime(2000, 1, 1),\n                                        regridder_type = :InterpolationsRegridder,\n                                        file_reader_kwargs = (; preprocess_func = unit_conversion_func),\n                                        compose_function)","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"The same arguments (excluding reference_date) could be passed to a SpaceVaryingInput to compose multiple input variables with that type.","category":"page"},{"location":"inputs/#Extrapolation-boundary-conditions","page":"Space and Time Inputs","title":"Extrapolation boundary conditions","text":"","category":"section"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"TimeVaryingInputs can have multiple boundary conditions for extrapolation. By default, the Throw condition is used, meaning that interpolating onto a point that is outside the range of definition of the data is not allowed. Other boundary conditions are allowed. With the Flat boundary condition, when interpolating outside of the range of definition, return the value of the of closest boundary is used instead.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"Another boundary condition that is often useful is PeriodicCalendar, which repeats data over and over.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"In general PeriodicCalendar takes two inputs: the period and repeat_date. The repeat period is a Dates.DatePeriod (e.g., Dates.Year(1)) that defines the duration of the period that has to be repeated. The repeat_date defines what date range needs to be repeated. For example, if period = Dates.Month(1) and repeat_date = Dates.Date(1993, 11), November 1993 will be repeated.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"The two inputs are not required. When they are not provided, ClimaUtilities will assume that the input data constitutes one period and use that. For example, if the data is defined from t0 to t1 (e.g., 1 and 5), interpolating over t > t1 (e.g., 7) is equivalent to interpolating to t* where t* is the modulus of t and the range (3 in this case). In this case, PeriodicCalendar requires the data to be uniformly spaced in time. To enable this boundary condition, pass LinearInterpolation(PeriodicCalendar()) to the TimeVaryingInput (or NearestNeighbor(PeriodicCalendar())).","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"Note: this PeriodicCalendar is different from what you might be used to, where the identification is t1 = t0. Here, we identify t1 + dt = t0. This is so that we can use it to repeat calendar data.","category":"page"},{"location":"inputs/#LinearPeriodFillingInterpolation","page":"Space and Time Inputs","title":"LinearPeriodFillingInterpolation","text":"","category":"section"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"Often, data is not available at the frequency we would like it to be. For example, we might have hourly data for a given quantity but only on the 15th of the month. Performing linear interpolation with data with this type of gap is typically not accurate. Consider the example of a quantity with a diurnal cycle but measured only once a month. If we were to blindly perform linear interpolation, we would find that the diurnal cycle is completely removed for every day of the month but the 15th. This is because we would interpolate the last point for the day of a given month, with the first for the following.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"LinearPeriodFillingInterpolation is an interpolation method that solves this problem by preserving periodic structures. This is accomplished by performing linear interpolation across corresponding periods (in the case of the day, across corresponding hours of different days). For more information, please refer to the docstring.","category":"page"},{"location":"inputs/#Example","page":"Space and Time Inputs","title":"Example","text":"","category":"section"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"Let target_space be the computational domain (a ClimaCore Space) and cesm_albedo.nc a NetCDF file containing albedo data as a function of time in a variable named alb.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"import ClimaUtilities: TimeVaryingInputs\nimport ClimaCore\nimport NCDatasets\nimport ClimaCoreTempestRemap\n# Loading ClimaCore, NCDatasets, ClimaCoreTempestRemap loads the extensions we need\n\nfunction evolve_model(albedo_tv, albedo_field)\n    new_t = t + dt\n    # First, we update the albedo to the new time\n    evaluate!(albedo_field, albedo_tv, new_t)\n    # Now we can do all the operations we want we albedo_filed\n    # rhs = ...\nend\n\n# Let us prepare an empty Field that will contain the albedo\nalbedo_field = zero(target_space)\n\n# If the albedo is an analytic function of time\nalbedo_tv_an = TimeVaryingInput((t) -> 0.5)\n\n# If the albedo comes from data\n\n# reference_date is the calendar date at the beginning of our simulation\nreference_date = Dates.DateTime(2000, 1, 1)\nalbedo_tv = TimeVaryingInputs.TimeVaryingInput(\"cesem_albedo.nc\", \"alb\", target_space;\n                                               reference_date, regridder_kwargs = (; regrid_dir = \"/tmp\"))\n# When using data from files, the data is automatically interpolated to the correct\n# time\n\n# In either cases, we can always call evolve_model(albedo_tv, albedo_field), so\n# model developers do not have to worry about anything :)","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"As seen in this example, Inputs can take keyword arguments and pass them down to other constructors. This often used to preprocess files that are being read (most commonly to change units). For example, if we want to multiply the albedo by a factor of 100, we would change albedo_tv with","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"albedo_tv = TimeVaryingInputs.TimeVaryingInput(\"cesem_albedo.nc\", \"alb\", target_space;\n                                               reference_date, regridder_kwargs = (; regrid_dir = \"/tmp\"),\n                                               file_reader_kwargs = (; preprocess_func = (x) -> 100x))","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"!!! note In this example we used the TempestRegridder. This is not the     best choice in most cases because the TempestRegridder is slower,     and not well-compatible with MPI and GPUs (ClimaUtilities implements     workarounds for this, so the code would still work).     InterpolationsRegridder should be preferred, unless there is a     strict requirement of conservation: while TempestRegridder is     guaranteed to conserve various properties, InterpolationsRegridder     is not.","category":"page"},{"location":"inputs/#SpaceVaryingInputs","page":"Space and Time Inputs","title":"SpaceVaryingInputs","text":"","category":"section"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"This extension is loaded when loading ClimaCore is loaded. In addition to this, if NetCDF files are used, NCDatasets has to be loaded too. Finally, a Regridder is needed (which might require importing additional packages).","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"SpaceVaryingInputs uses the same building blocks as TimeVaryingInput (chiefly the DataHandling module) to construct a Field from different sources.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"SpaceVaryingInputs support:","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"analytic functions of coordinates;\npairs of 1D arrays (for columns);\n2/3D NetCDF files (including composing multiple variables from one or more files into one variable).","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"In some ways, a SpaceVaryingInput can be thought as an alternative constructor for a ClimaCore Field.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"It is possible to pass down keyword arguments to underlying constructors in the Regridder with the regridder_kwargs and file_reader_kwargs. These have to be a named tuple or a dictionary that maps Symbols to values.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"SpaceVaryingInputs support reading individual input variables from NetCDF files, as well as composing multiple input variables into one SpaceVaryingInput. See the TimeVaryingInput \"NetCDF file inputs\" section for more information about this feature.","category":"page"},{"location":"inputs/#Example-2","page":"Space and Time Inputs","title":"Example","text":"","category":"section"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"Let target_space be a ClimaCore Space where we want the Field to be defined on and cesm_albedo.nc a NetCDF file containing albedo data as a time in a variable named alb.","category":"page"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"import ClimaUtilities: SpaceVaryingInputs\nimport ClimaCore\nimport NCDatasets\nimport ClimaCoreTempestRemap\n# Loading ClimaCore, NCDatasets, ClimaCoreTempestRemap loads the extensions we need\n\n# Albedo as an analytic function of lat and lon\nalbedo_latlon_fun = (coord) -> 0.5 * coord.long * coord.lat\n\nalbedo = SpaceVaryingInputs.SpaceVaryingInput(albedo_latlon_fun)\n\nalbedo_from_file = SpaceVaryingInputs.SpaceVaryingInput(\"cesm_albedo.nc\", \"alb\", target_space, regridder_kwargs = (; regrid_dir = \"/tmp\"))","category":"page"},{"location":"inputs/#API","page":"Space and Time Inputs","title":"API","text":"","category":"section"},{"location":"inputs/","page":"Space and Time Inputs","title":"Space and Time Inputs","text":"ClimaUtilities.SpaceVaryingInputs.SpaceVaryingInput\nClimaUtilities.TimeVaryingInputs.AbstractInterpolationMethod\nClimaUtilities.TimeVaryingInputs.AbstractInterpolationBoundaryMethod\nClimaUtilities.TimeVaryingInputs.NearestNeighbor\nClimaUtilities.TimeVaryingInputs.LinearInterpolation\nClimaUtilities.TimeVaryingInputs.Throw\nClimaUtilities.TimeVaryingInputs.PeriodicCalendar\nClimaUtilities.TimeVaryingInputs.Flat\nClimaUtilities.TimeVaryingInputs.evaluate!\nClimaUtilities.TimeVaryingInputs.extrapolation_bc\nBase.in\nBase.close","category":"page"},{"location":"inputs/#ClimaUtilities.SpaceVaryingInputs.SpaceVaryingInput","page":"Space and Time Inputs","title":"ClimaUtilities.SpaceVaryingInputs.SpaceVaryingInput","text":"SpaceVaryingInput(data_function::Function, space::ClimaCore.Spaces.AbstractSpace)\n\nReturns the parameter field to be used in the model; appropriate when a parameter is defined using a function of the coordinates of the space.\n\nPass the `data\" as a functiondata_function` which takes coordinates as arguments, and  the ClimaCore space of the model simulation.\n\nThis returns a scalar field. Note that data_function is broadcasted over the coordinate field. Internally, inside your function, this must be unpacked (coords.lat, coords.lon, e.g.) for use of the coordinate values directly.\n\n\n\n\n\nfunction SpaceVaryingInput(\n    data_z::AbstractArray,\n    data_values::AbstractArray,\n    space::S,\n) where {S <: ClimaCore.Spaces.CenterFiniteDifferenceSpace}\n\nGiven a set of depths data_z and the observed values data_values at those depths, create an interpolated field of values at each value of z in the model grid - defined implicitly by space.\n\nReturns a ClimaCore.Fields.Field of scalars.\n\n\n\n\n\nSpaceVaryingInputs.SpaceVaryingInput(\n    data_z::AbstractArray,\n    data_values::NamedTuple,\n    space::S,\n    dest_type::Type{DT},\n) where {\n    S <: ClimaCore.Spaces.CenterFiniteDifferenceSpace,\n    DT,\n}\n\nReturns a field of parameter structs to be used in the model; appropriate when the parameter struct values vary in depth; the dest_type argument is the struct type - we assumed that your struct as a constructor which accepts the values of its arguments by kwarg,\n\ndata_z is where the measured values were obtained,\ndata_values is a NamedTuple with keys equal to the argument names\n\nof the struct, and with values equal to an array of measured values,\n\nspace defines the model grid.\n\nAs an example, we can create a field of vanGenuchten structs as follows. This struct requires two parameters, α and n. Let's assume that we have measurements of these as a function of depth at the locations given by data_z, called data_α and data_n. Then we can write vG_field = SpaceVaryingInput(data_z, (;α = data_α, n = data_n), space, vanGenuchten{Float32}). Under the hood, at each point in the model grid, we will create vanGenuchten{Float32}(;α = interp_α, n = interp_n), where interp indicates the interpolated value at the model depth.\n\nReturns a ClimaCore.Fields.Field of type DT.\n\n\n\n\n\nSpaceVaryingInput(data_handler::DataHandler)\nSpaceVaryingInput(file_paths::Union{AbstractString, AbstractArray{String}},\n                  varnames::Union{AbstractString, AbstractArray{String}},\n                  target_space::Spaces.AbstractSpace;\n                  regridder_type::Symbol,\n                  regridder_kwargs = (),\n                  file_reader_kwargs = ())\n\nReturns the parameter field to be used in the model; appropriate when a parameter is defined on the surface of the Earth.\n\nReturns a ClimaCore.Fields.Field of scalars; analogous to the 1D case which also returns a ClimaCore.Fields.Field of scalars.\n\n\n\n\n\n","category":"function"},{"location":"inputs/#ClimaUtilities.TimeVaryingInputs.AbstractInterpolationMethod","page":"Space and Time Inputs","title":"ClimaUtilities.TimeVaryingInputs.AbstractInterpolationMethod","text":"AbstractInterpolationMethod\n\nDefines how to perform interpolation.\n\nNot all the TimeVaryingInputs support all the interpolation methods (e.g., no interpolation methods are supported when the given function is analytic).\n\nAbstractInterpolationMethods have to implement a extrapolation_bc field.\n\n\n\n\n\n","category":"type"},{"location":"inputs/#ClimaUtilities.TimeVaryingInputs.AbstractInterpolationBoundaryMethod","page":"Space and Time Inputs","title":"ClimaUtilities.TimeVaryingInputs.AbstractInterpolationBoundaryMethod","text":"AbstractInterpolationBoundaryMethod\n\nDefines how to handle values outside of the data boundary.\n\nNot all the AbstractInterpolationMethod support all the AbstractInterpolationBoundaryMethods.\n\n\n\n\n\n","category":"type"},{"location":"inputs/#ClimaUtilities.TimeVaryingInputs.NearestNeighbor","page":"Space and Time Inputs","title":"ClimaUtilities.TimeVaryingInputs.NearestNeighbor","text":"NearestNeighbor(extrapolation_bc::AbstractInterpolationBoundaryMethod)\n\nReturn the value corresponding to the point closest to the input time.\n\nextrapolation_bc specifies how to deal with out of boundary values. The default value is Throw.\n\n\n\n\n\n","category":"type"},{"location":"inputs/#ClimaUtilities.TimeVaryingInputs.LinearInterpolation","page":"Space and Time Inputs","title":"ClimaUtilities.TimeVaryingInputs.LinearInterpolation","text":"LinearInterpolation(extrapolation_bc::AbstractInterpolationBoundaryMethod)\n\nPerform linear interpolation between the two neighboring points.\n\nextrapolation_bc specifies how to deal with out of boundary values. The default value is Throw.\n\n\n\n\n\n","category":"type"},{"location":"inputs/#ClimaUtilities.TimeVaryingInputs.Throw","page":"Space and Time Inputs","title":"ClimaUtilities.TimeVaryingInputs.Throw","text":"Throw\n\nThrow an error when interpolating outside of range.\n\n\n\n\n\n","category":"type"},{"location":"inputs/#ClimaUtilities.TimeVaryingInputs.PeriodicCalendar","page":"Space and Time Inputs","title":"ClimaUtilities.TimeVaryingInputs.PeriodicCalendar","text":"PeriodicCalendar\n\nRepeat data periodically.\n\nPeriodicCalendar has two modes of operation:\n\nFirst, when provided with a period (described a DatePeriod, e.g., Dates.Month(1) or Dates.Year(1)), assume that the provided data is repeated over that calendar period. A date can be passed too, indicating what data to use. Only simple periods (e.g., Dates.Month(1)) are supported. When provided a period, a repeat_date is required too. This is the period of time that is repeated. For example, if period = Dates.Month(1) and repeat_date = Dates.Date(1993, 11), November 1993 is repeated (if available in the input data).\n\nNote: Passing a period is not supported by all the interpolators (e.g., when reading from\n\n1D files).\n\nSecond, if no period is provided, when interpolating outside of range, restart from the beginning.\n\nFor example, if the data is defined from t0 = 0 to t1 = 10, extrapolating at t=13 is equivalent to interpolating at t=2. In practice, we identify t1 + dt to be t0 again. This is different from what you might be used to for periodic boundary conditions, where the identification is t1 = t0.\n\nThis second mode of operation PeriodicCalendar requires data to be uniformly sampled in time.\n\nIf the data is defined on a calendar year, this second mode of operation is equivalent to using the first mode with period = Dates.Year (same with other periods).\n\n\n\n\n\n","category":"type"},{"location":"inputs/#ClimaUtilities.TimeVaryingInputs.Flat","page":"Space and Time Inputs","title":"ClimaUtilities.TimeVaryingInputs.Flat","text":"Flat\n\nWhen interpolating outside of range, use the boundary value.\n\nFor example, if the data is defined from t0 = 0 to t1 = 10, extrapolating at t=13 returns the value at t1 = 10. When interpolating at t=-3, use t0 = 0.\n\n\n\n\n\n","category":"type"},{"location":"inputs/#ClimaUtilities.TimeVaryingInputs.evaluate!","page":"Space and Time Inputs","title":"ClimaUtilities.TimeVaryingInputs.evaluate!","text":"evaluate!(dest, input, time, args...; kwargs...)\n\nEvaluate the input at the given time, writing the output in-place to dest.\n\nDepending on the details of input, this function might do I/O and communication.\n\nExtra arguments\n\nargs and kwargs are used only when the input is a non-interpolating function, e.g., an analytic one. In that case, args and kwargs are passed down to the function itself.\n\n\n\n\n\n","category":"function"},{"location":"inputs/#ClimaUtilities.TimeVaryingInputs.extrapolation_bc","page":"Space and Time Inputs","title":"ClimaUtilities.TimeVaryingInputs.extrapolation_bc","text":"extrapolation_bc(aim::AbstractInterpolationMethod)\n\nReturn the interpolation boundary conditions associated to aim.\n\n\n\n\n\n","category":"function"},{"location":"inputs/#Base.in","page":"Space and Time Inputs","title":"Base.in","text":"in(time, itp::InterpolatingTimeVaryingInput23D)\n\nCheck if the given time is in the range of definition for itp.\n\n\n\n\n\nin(time, itp::InterpolatingTimeVaryingInput23D)\n\nCheck if the given time is in the range of definition for itp.\n\n\n\n\n\n","category":"function"},{"location":"filereaders/#FileReaders","page":"FileReaders","title":"FileReaders","text":"","category":"section"},{"location":"filereaders/","page":"FileReaders","title":"FileReaders","text":"Reading files is a common need for most scientific projects. This can come with a series of problems that have to be solved, from performance (accessing can be a very computationally expensive operation), to dealing with multiple files that are logically connected. The FileReaders provides an abstraction layer to decouple the scientific needs with the technical implementation so that file processing can be optimized and extended independently of the rest of the model.","category":"page"},{"location":"filereaders/","page":"FileReaders","title":"FileReaders","text":"At this point, the implemented FileReaders are always linked to a specific variable and they come with a caching system to avoid unnecessary reads.","category":"page"},{"location":"filereaders/","page":"FileReaders","title":"FileReaders","text":"Future extensions might include:","category":"page"},{"location":"filereaders/","page":"FileReaders","title":"FileReaders","text":"dealing with multiple files containing the same variables (e.g. time series when the dates are split in different files);\ndoing chunked reads;\nasync reads.","category":"page"},{"location":"filereaders/#NCFileReaders","page":"FileReaders","title":"NCFileReaders","text":"","category":"section"},{"location":"filereaders/","page":"FileReaders","title":"FileReaders","text":"This extension is loaded when loading NCDatasets","category":"page"},{"location":"filereaders/","page":"FileReaders","title":"FileReaders","text":"The only file reader currently implemented is the NCFileReader, used to read NetCDF files. Each NCFileReader is associated to one particular file and variable (but multiple NCFileReaders can share the same file).","category":"page"},{"location":"filereaders/","page":"FileReaders","title":"FileReaders","text":"Once created, NCFileReader is accessed with the read(file_reader, date) function, which returns the Array associated to given date (if available). The date can be omitted if the data is static.","category":"page"},{"location":"filereaders/","page":"FileReaders","title":"FileReaders","text":"NCFileReaders implement two additional features: (1) optional preprocessing, and (2) cache reads. NCFileReaders can be created with a preprocessing_func keyword argument, function is applied to the read datasets when reading. preprocessing_func should be a lightweight function, such as removing NaNs or changing units. Every time read(file_reader, date) is called, the NCFileReader checks if the date is currently stored in the cache. If yes, it just returns the value (without accessing the disk). If not, it reads and process the data and adds it to the cache. This uses a least-recently-used (LRU) cache implemented in DataStructures, which removes the least-recently-used data stored in the cache when its maximum size is reached (the default max size is 128).","category":"page"},{"location":"filereaders/","page":"FileReaders","title":"FileReaders","text":"It is good practice to always close the NCFileReaders when they are no longer needed. The function close_all_ncfiles closes all the ones that are currently open.","category":"page"},{"location":"filereaders/#Example","page":"FileReaders","title":"Example","text":"","category":"section"},{"location":"filereaders/","page":"FileReaders","title":"FileReaders","text":"Assume you have a file era5_2000.nc, which contains two variables u and v, defined for the year 2000.","category":"page"},{"location":"filereaders/","page":"FileReaders","title":"FileReaders","text":"import ClimaUtilities.FileReaders\nimport NCDatasets\n# Loading NCDatasets automatically loads `NCFileReaders`\n\nu_var = FileReaders.NCFileReader(\"era5_2000.nc\", \"u\")\n# Change units for v\nv_var = FileReaders.NCFileReader(\"era5_2000.nc\", \"u\", preprocess_func = x -> 1000x)\n\ndates = FileReaders.available_dates(u_var)\n# dates is a vector of Dates.DateTime\n\nfirst_date = dates[begin]\n\n# The first time we call read, the file is accessed and read\nu_array = FileReaders.read(u_var, first_date)\n# As the name suggests, u_array is an Array\n\n# All the other times, we access the cache, so no IO operation is involved\nu_array_again = FileReaders.read(u_var, first_date)\n\nclose(u_var)\nclose(v_var)\n# Alternatively: FileReaders.close_all_ncfiles()","category":"page"},{"location":"filereaders/#API","page":"FileReaders","title":"API","text":"","category":"section"},{"location":"filereaders/","page":"FileReaders","title":"FileReaders","text":"ClimaUtilities.FileReaders.NCFileReader\nClimaUtilities.FileReaders.read\nClimaUtilities.FileReaders.available_dates\nClimaUtilities.FileReaders.close_all_ncfiles\nBase.close","category":"page"},{"location":"filereaders/#ClimaUtilities.FileReaders.NCFileReader","page":"FileReaders","title":"ClimaUtilities.FileReaders.NCFileReader","text":"FileReaders.NCFileReader(\n    file_path::AbstractString,\n    varname::AbstractString;\n    preprocess_func = identity,\n    cache_max_size:Int = 128,\n)\n\nA struct to efficiently read and process NetCDF files.\n\n\n\n\n\n","category":"function"},{"location":"filereaders/#ClimaUtilities.FileReaders.read","page":"FileReaders","title":"ClimaUtilities.FileReaders.read","text":"read(file_reader::NCFileReader, date::Dates.DateTime)\n\nRead and preprocess the data at the given date.\n\n\n\n\n\nread(file_reader::NCFileReader)\n\nRead and preprocess data (for static datasets).\n\n\n\n\n\n","category":"function"},{"location":"filereaders/#ClimaUtilities.FileReaders.available_dates","page":"FileReaders","title":"ClimaUtilities.FileReaders.available_dates","text":"available_dates(file_reader::NCFileReader)\n\nReturns the dates in the given file.\n\n\n\n\n\n","category":"function"},{"location":"filereaders/#ClimaUtilities.FileReaders.close_all_ncfiles","page":"FileReaders","title":"ClimaUtilities.FileReaders.close_all_ncfiles","text":"close_all_ncfiles()\n\nClose all the NCFileReader currently open.\n\n\n\n\n\n","category":"function"},{"location":"filereaders/#Base.close","page":"FileReaders","title":"Base.close","text":"close(data_handler::DataHandler)\n\nClose all files associated to the given data_handler.\n\n\n\n\n\nclose(time_varying_input::TimeVaryingInputs.AbstractTimeVaryingInput)\n\nClose files associated to the time_varying_input.\n\n\n\n\n\nclose(time_varying_input::InterpolatingTimeVaryingInput23D)\n\nClose files associated to the time_varying_input.\n\n\n\n\n\nclose(file_reader::NCFileReader)\n\nClose NCFileReader. If no other NCFileReader is using the same file, close the NetCDF file.\n\n\n\n\n\n","category":"function"}]
}
